{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5mKM5H28GVV",
        "outputId": "cdeede7d-1e11-4c3b-9297-ccc4d84b88de"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LiFOCZL6VZV",
        "outputId": "88874205-0af4-4b65-86e8-b21a815852e3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-1424nauz\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-1424nauz\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 5741c522547756ac4bb7a16df32106a15efb8a57\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: nvcc4jupyter\n",
            "  Building wheel for nvcc4jupyter (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nvcc4jupyter: filename=nvcc4jupyter-1.2.1-py3-none-any.whl size=10741 sha256=1c43b610d84440f376c57bb0b3d20f87e2433fdb6f06eb98d5fd7c81c461a971\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-nhehoqnu/wheels/a8/b9/18/23f8ef71ceb0f63297dd1903aedd067e6243a68ea756d6feea\n",
            "Successfully built nvcc4jupyter\n",
            "Installing collected packages: nvcc4jupyter\n",
            "Successfully installed nvcc4jupyter-1.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Vector Addition:\n",
        "\n",
        "%%writefile vector_Addition_2.cu\n",
        "#include<iostream>\n",
        "#include<cuda.h>\n",
        "#include<cuda_runtime.h>\n",
        "#define BLOCK_SIZE 256  // Optimal for GPU usage\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "void fill_array(int *arr, int size) {\n",
        "    for (int i = 0; i < size; i++) {\n",
        "        arr[i] = rand() % 100;\n",
        "    }\n",
        "}\n",
        "\n",
        "void add_cpu(int *arr1, int *arr2, int *result, int size) {\n",
        "    for (int i = 0; i < size; i++) {\n",
        "        result[i] = arr1[i] + arr2[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "void print_matrix(int *arr, int size) {\n",
        "    for (int i = 0; i < size; i++) {\n",
        "        cout << arr[i] << \" \";\n",
        "    }\n",
        "    cout << endl;\n",
        "}\n",
        "\n",
        "__global__ void add(int *arr1, int *arr2, int *arr3, int size) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (idx < size) {\n",
        "        arr3[idx] = arr1[idx] + arr2[idx];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int size;\n",
        "    cout << \"Enter size of vector: \";\n",
        "    cin >> size;\n",
        "    int *arr1_cpu = new int[size], *arr2_cpu = new int[size], *result_cpu = new int[size];\n",
        "\n",
        "    fill_array(arr1_cpu, size);\n",
        "    cout << \"Array 1: \";\n",
        "    print_matrix(arr1_cpu, size);\n",
        "    fill_array(arr2_cpu, size);\n",
        "    cout << \"Array 2: \";\n",
        "    print_matrix(arr2_cpu, size);\n",
        "\n",
        "    int *arr1_gpu, *arr2_gpu, *result_gpu;\n",
        "    cudaMalloc(&arr1_gpu, size * sizeof(int));\n",
        "    cudaMalloc(&arr2_gpu, size * sizeof(int));\n",
        "    cudaMalloc(&result_gpu, size * sizeof(int));\n",
        "\n",
        "    cudaMemcpy(arr1_gpu, arr1_cpu, size * sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(arr2_gpu, arr2_cpu, size * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // GPU timing\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "    cudaEventRecord(start);\n",
        "\n",
        "    dim3 dimGrid((size + BLOCK_SIZE - 1) / BLOCK_SIZE), dimBlock(BLOCK_SIZE);\n",
        "    add<<<dimGrid, dimBlock>>>(arr1_gpu, arr2_gpu, result_gpu, size);\n",
        "\n",
        "    cudaEventRecord(stop);\n",
        "    cudaEventSynchronize(stop);\n",
        "    float gpuTime = 0;\n",
        "    cudaEventElapsedTime(&gpuTime, start, stop);\n",
        "\n",
        "    cudaMemcpy(result_cpu, result_gpu, size * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    cout << \"GPU result:\\n\";\n",
        "    print_matrix(result_cpu, size);\n",
        "    cout << \"GPU Elapsed Time = \" << gpuTime << \" milliseconds\" << endl;\n",
        "\n",
        "    // CPU timing\n",
        "    cudaEventRecord(start);\n",
        "    add_cpu(arr1_cpu, arr2_cpu, result_cpu, size);\n",
        "    cudaEventRecord(stop);\n",
        "    cudaEventSynchronize(stop);\n",
        "    float cpuTime = 0;\n",
        "    cudaEventElapsedTime(&cpuTime, start, stop);\n",
        "\n",
        "    cout << \"CPU result:\\n\";\n",
        "    print_matrix(result_cpu, size);\n",
        "    cout << \"CPU Elapsed Time = \" << cpuTime << \" milliseconds\" << endl;\n",
        "\n",
        "    cudaEventDestroy(start);\n",
        "    cudaEventDestroy(stop);\n",
        "    cudaFree(arr1_gpu);\n",
        "    cudaFree(arr2_gpu);\n",
        "    cudaFree(result_gpu);\n",
        "    delete[] arr1_cpu;\n",
        "    delete[] arr2_cpu;\n",
        "    delete[] result_cpu;\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "id": "tNlV6P3xONzl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -o vector_Addition_2 vector_Addition_2.cu\n",
        "!./vector_Addition_2"
      ],
      "metadata": {
        "id": "UUAw4ylSPXCc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrix Mul\n",
        "\n",
        "%%writefile matmul.cu\n",
        "#include <iostream>\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime.h>\n",
        "#define BLOCK_SIZE 256  // Suitable for many devices; consider your GPU's specs for optimization\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "// Function to initialize matrix with random values\n",
        "void initialize_matrix(int *array, int rows, int cols) {\n",
        "    for (int i = 0; i < rows; i++) {\n",
        "        for (int j = 0; j < cols; j++) {\n",
        "            array[i * cols + j] = rand() % 10;  // Keeping numbers small for easy visualization\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "// Function to print matrix\n",
        "/*void print_matrix(int *array, int rows, int cols) {\n",
        "    for (int i = 0; i < rows; i++) {\n",
        "        for (int j = 0; j < cols; j++) {\n",
        "            cout << array[i * cols + j] << \" \";\n",
        "        }\n",
        "        cout << endl;\n",
        "    }\n",
        "}*/\n",
        "\n",
        "// CPU matrix multiplication\n",
        "void matrix_multiplication_cpu(int *a, int *b, int *c, int common, int c_rows, int c_cols) {\n",
        "    for (int i = 0; i < c_rows; i++) {\n",
        "        for (int j = 0; j < c_cols; j++) {\n",
        "            int sum = 0;\n",
        "            for (int k = 0; k < common; k++) {\n",
        "                sum += a[i * common + k] * b[k * c_cols + j];\n",
        "            }\n",
        "            c[i * c_cols + j] = sum;\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "// GPU kernel for matrix multiplication\n",
        "__global__ void matrix_multiply(int *a, int *b, int *c, int common, int c_rows, int c_cols) {\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (row < c_rows && col < c_cols) {\n",
        "        int sum = 0;\n",
        "        for (int k = 0; k < common; k++) {\n",
        "            sum += a[row * common + k] * b[k * c_cols + col];\n",
        "        }\n",
        "        c[row * c_cols + col] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int A_rows, A_cols, B_cols;\n",
        "    cout << \"Dimensions of matrix 1:\\nRows: \";\n",
        "    cin >> A_rows;\n",
        "    cout << \"Columns: \";\n",
        "    cin >> A_cols;\n",
        "    cout << \"Dimensions of matrix 2:\\nRows: \" << A_cols << \"\\nColumns: \";\n",
        "    cin >> B_cols;\n",
        "\n",
        "    int B_rows = A_cols, C_rows = A_rows, C_cols = B_cols;\n",
        "    int *A = new int[A_rows * A_cols];\n",
        "    int *B = new int[B_rows * B_cols];\n",
        "    int *C = new int[C_rows * C_cols];\n",
        "\n",
        "    initialize_matrix(A, A_rows, A_cols);\n",
        "    /*cout << \"Matrix 1\\n\";\n",
        "    print_matrix(A, A_rows, A_cols);*/\n",
        "\n",
        "    initialize_matrix(B, B_rows, B_cols);\n",
        "    /* cout << \"Matrix 2\\n\";\n",
        "    print_matrix(B, B_rows, B_cols);*/\n",
        "\n",
        "    int *d_A, *d_B, *d_C;\n",
        "    cudaMalloc(&d_A, A_rows * A_cols * sizeof(int));\n",
        "    cudaMalloc(&d_B, B_rows * B_cols * sizeof(int));\n",
        "    cudaMalloc(&d_C, C_rows * C_cols * sizeof(int));\n",
        "\n",
        "    cudaMemcpy(d_A, A, A_rows * A_cols * sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, B, B_rows * B_cols * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    dim3 dimBlock(BLOCK_SIZE, BLOCK_SIZE);\n",
        "    dim3 dimGrid((C_cols + BLOCK_SIZE - 1) / BLOCK_SIZE, (C_rows + BLOCK_SIZE - 1) / BLOCK_SIZE);\n",
        "\n",
        "    float gpuTime = 0, cpuTime = 0;\n",
        "    cudaEvent_t start, stop;\n",
        "\n",
        "    // GPU Timing\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "    cudaEventRecord(start);\n",
        "\n",
        "    matrix_multiply<<<dimGrid, dimBlock>>>(d_A, d_B, d_C, A_cols, C_rows, C_cols);\n",
        "\n",
        "    cudaEventRecord(stop);\n",
        "    cudaEventSynchronize(stop);\n",
        "    cudaEventElapsedTime(&gpuTime, start, stop);\n",
        "    cudaMemcpy(C, d_C, C_rows * C_cols * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    cout << \"GPU result:\\n\";\n",
        "    // print_matrix(C, C_rows, C_cols);\n",
        "    cout << \"GPU Elapsed Time = \" << gpuTime << \" ms\" << endl;\n",
        "\n",
        "    // CPU Timing\n",
        "    cudaEventRecord(start);\n",
        "    matrix_multiplication_cpu(A, B, C, A_cols, C_rows, C_cols);\n",
        "    cudaEventRecord(stop);\n",
        "    cudaEventSynchronize(stop);\n",
        "    cudaEventElapsedTime(&cpuTime, start, stop);\n",
        "\n",
        "    cout << \"CPU result:\\n\";\n",
        "    // print_matrix(C, C_rows, C_cols);\n",
        "    cout << \"CPU Elapsed Time = \" << cpuTime << \" ms\" << endl;\n",
        "\n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_B);\n",
        "    cudaFree(d_C);\n",
        "    delete[] A;\n",
        "    delete[] B;\n",
        "    delete[] C;\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXEXRT3PnL5u",
        "outputId": "32da731e-fba7-4733-853b-8b5bf90f3452"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting matmul.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -o matmul matmul.cu\n",
        "!./matmul"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAieN2Sfoq61",
        "outputId": "f583bc9c-5e2d-4ada-e601-74bde29d9787"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensions of matrix 1:\n",
            "Rows: 300\n",
            "Columns: 800\n",
            "Dimensions of matrix 2:\n",
            "Rows: 800\n",
            "Columns: 250\n",
            "GPU result:\n",
            "GPU Elapsed Time = 0.170336 ms\n",
            "CPU result:\n",
            "CPU Elapsed Time = 242.038 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Below is an inefficient code for the practical, so refer to the above codes"
      ],
      "metadata": {
        "id": "Hf0YoxMSqH1E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile vector_Addition.cu\n",
        "# #include<iostream>\n",
        "# #include<bits/stdc++.h>\n",
        "# #include<cuda.h>\n",
        "# #define BLOCK_SIZE 16\n",
        "# using namespace std;\n",
        "\n",
        "# void fill_array(int *arr,int size){\n",
        "#     for(int i = 0;i < size; i++){\n",
        "#         arr[i] = rand() % 100;\n",
        "#     }\n",
        "# }\n",
        "\n",
        "# void add_cpu(int *arr1, int *arr2, int *result, int size){\n",
        "#     for(int i = 0;i < size; i++){\n",
        "#         result[i] = arr1[i] + arr2[i];\n",
        "#     }\n",
        "# }\n",
        "\n",
        "# void print_matrix(int *arr, int size){\n",
        "#     for(int i = 0; i < size; i++){\n",
        "#         cout << arr[i] << \" \";\n",
        "#     }\n",
        "#     cout << endl;\n",
        "# }\n",
        "\n",
        "# __global__ void add(int *arr1, int *arr2, int *arr3,int size){\n",
        "#     int block_id = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "#     if(block_id < size){\n",
        "#         arr3[block_id] = arr1[block_id] + arr2[block_id];\n",
        "#     }\n",
        "# }\n",
        "\n",
        "# int main(){\n",
        "#     int *arr1_cpu,*arr2_cpu,*result_cpu;\n",
        "#     int size;\n",
        "#     cout << \"Enter size of vector: \";\n",
        "#     cin >> size;\n",
        "\n",
        "#     arr1_cpu = new int[size];\n",
        "#     arr2_cpu = new int[size];\n",
        "#     result_cpu = new int[size];\n",
        "\n",
        "#     fill_array(arr1_cpu,size);\n",
        "#     cout << \"Array 1: \";\n",
        "#     print_matrix(arr1_cpu,size);\n",
        "#     fill_array(arr2_cpu,size);\n",
        "#     cout << \"Array 2: \";\n",
        "#     print_matrix(arr2_cpu,size);\n",
        "\n",
        "#     int *arr1_gpu,*arr2_gpu,*result_gpu;\n",
        "\n",
        "#     cudaMallocManaged(&arr1_gpu, size * sizeof(int));\n",
        "#     cudaMallocManaged(&arr2_gpu, size * sizeof(int));\n",
        "#     cudaMallocManaged(&result_gpu, size * sizeof(int));\n",
        "\n",
        "#     cudaMemcpy(arr1_gpu,arr1_cpu,size * sizeof(int),cudaMemcpyHostToDevice);\n",
        "#     cudaMemcpy(arr2_gpu,arr2_cpu,size * sizeof(int),cudaMemcpyHostToDevice);\n",
        "#     cudaEvent_t start,stop;\n",
        "#     float elapsedTime;\n",
        "\n",
        "#     dim3 dimGrid(size + BLOCK_SIZE - 1 / BLOCK_SIZE);\n",
        "#     dim3 dimBlock(BLOCK_SIZE);\n",
        "\n",
        "#     cudaEventCreate(&start);\n",
        "#     cudaEventCreate(&stop);\n",
        "#     cudaEventRecord(start,0);\n",
        "\n",
        "#     add<<<dimGrid,dimBlock>>>(arr1_gpu,arr2_gpu,result_gpu,size);\n",
        "#     cudaEventRecord(stop,0);\n",
        "#     cudaEventSynchronize(stop);\n",
        "#     cudaEventElapsedTime(&elapsedTime,start,stop);\n",
        "#     cudaEventDestroy(start);\n",
        "#     cudaEventDestroy(stop);\n",
        "#     cudaMemcpy(result_cpu,result_gpu,size * sizeof(int),cudaMemcpyDeviceToHost);\n",
        "#     cout << \"GPU result:\\n\";\n",
        "#     print_matrix(result_cpu,size);\n",
        "#     cout<<\"Elapsed Time = \"<<elapsedTime<<\" milliseconds\" << endl;\n",
        "#     cudaFree(arr1_gpu);\n",
        "#     cudaFree(arr2_gpu);\n",
        "#     cudaFree(result_gpu);\n",
        "\n",
        "#     cudaEventCreate(&start);\n",
        "#     cudaEventCreate(&stop);\n",
        "#     cudaEventRecord(start,0);\n",
        "\n",
        "#     add_cpu(arr1_cpu,arr2_cpu,result_cpu,size);\n",
        "#     cudaEventRecord(stop,0);\n",
        "#     cudaEventSynchronize(stop);\n",
        "#     cudaEventElapsedTime(&elapsedTime,start,stop);\n",
        "#     cudaEventDestroy(start);\n",
        "#     cudaEventDestroy(stop);\n",
        "#     cout << \"CPU result:\\n\";\n",
        "#     print_matrix(result_cpu,size);\n",
        "#     cout<<\"Elapsed Time = \"<<elapsedTime<<\" milliseconds\" << endl;\n",
        "\n",
        "#     return 0;\n",
        "# }"
      ],
      "metadata": {
        "id": "_9sz5jIgIFFh"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !nvcc -o vector_Addition vector_Addition.cu\n",
        "# !./vector_Addition"
      ],
      "metadata": {
        "id": "UV8WB09xITmD"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile matmul.cu\n",
        "\n",
        "# #include<iostream>\n",
        "# #include<bits/stdc++.h>\n",
        "# #include<cuda.h>\n",
        "# #define BLOCK_SIZE 16\n",
        "\n",
        "# using namespace std;\n",
        "\n",
        "\n",
        "\n",
        "# void initialize_matrix(int *array, int rows, int cols){\n",
        "#     for(int i = 0 ; i < rows; i++){\n",
        "#         for(int j = 0; j < cols; j++){\n",
        "#             array[i*cols + j] = rand() % 10;\n",
        "#         }\n",
        "#     }\n",
        "# }\n",
        "\n",
        "# void print_matrix(int *array, int rows, int cols){\n",
        "#     for(int i = 0 ; i < rows; i++){\n",
        "#         for(int j = 0; j < cols; j++){\n",
        "#             cout << array[i*cols + j] << \" \";\n",
        "#         }\n",
        "#         cout << endl;\n",
        "#     }\n",
        "# }\n",
        "\n",
        "# void matrix_multiplication_cpu(int *a, int *b, int *c, int common, int c_rows,int c_cols){\n",
        "#     for(int i = 0; i < c_rows; i++){\n",
        "#         for(int j = 0; j < c_cols; j++){\n",
        "#             int sum = 0;\n",
        "#             for(int k = 0; k < common; k++){\n",
        "#                 sum += a[i*common + k] * b[k*c_cols + j];\n",
        "#             }\n",
        "#             c[i*c_cols + j] = sum;\n",
        "#         }\n",
        "#     }\n",
        "# }\n",
        "\n",
        "\n",
        "\n",
        "# __global__ void matrix_multiply(int *a, int *b, int *c, int c_rows, int common, int c_cols)\n",
        "# {\n",
        "#     int row = blockIdx.y*blockDim.y + threadIdx.y;\n",
        "#     int col = blockIdx.x*blockDim.x + threadIdx.x;\n",
        "#     int sum=0;\n",
        "\n",
        "#     if(col < c_cols && row < c_rows) {\n",
        "#       for(int j = 0 ;j < common;j++)\n",
        "#       {\n",
        "#           sum += a[row*common+j] * b[j*c_cols+col];\n",
        "#       }\n",
        "#       c[c_cols*row+col]=sum;\n",
        "#     }\n",
        "\n",
        "# }\n",
        "\n",
        "\n",
        "# int main(){\n",
        "\n",
        "#     int A_rows, A_cols, B_rows, B_cols, C_rows, C_cols;\n",
        "#     cout << \"Dimensions of matrix 1:\\n\";\n",
        "#     cout << \"Rows: \";\n",
        "#     cin >> A_rows;\n",
        "#     cout << \"Columns: \";\n",
        "#     cin >> A_cols;\n",
        "#     cout << \"Dimensions of matrix 2:\\n\";\n",
        "#     cout << \"Rows: \" << A_cols << endl << \"Columns: \";\n",
        "#     cin >> B_cols;\n",
        "#     B_rows = A_cols;\n",
        "#     C_rows = A_rows;\n",
        "#     C_cols = B_cols;\n",
        "\n",
        "#     int A_size = A_rows * A_cols;\n",
        "#     int B_size = B_rows * B_cols;\n",
        "#     int C_size = C_rows * C_cols;\n",
        "\n",
        "#     int *A, *B, *C;\n",
        "#     int *m1,*m2,*result;\n",
        "\n",
        "#     A = new int[A_size];\n",
        "#     B = new int[B_size];\n",
        "#     C = new int[C_size];\n",
        "\n",
        "#     initialize_matrix(A,A_rows,A_cols);\n",
        "#     cout << \"Matrix 1\\n\";\n",
        "#     print_matrix(A,A_rows,A_cols);\n",
        "#     initialize_matrix(B,B_rows,B_cols);\n",
        "#     cout << \"Matrix 2\\n\";\n",
        "#     print_matrix(B,B_rows,B_cols);\n",
        "\n",
        "#     cudaMallocManaged(&m1, A_size * sizeof(int));\n",
        "#     cudaMallocManaged(&m2, B_size * sizeof(int));\n",
        "#     cudaMallocManaged(&result, C_size * sizeof(int));\n",
        "\n",
        "#     cudaMemcpy(m1,A,A_size * sizeof(int), cudaMemcpyHostToDevice);\n",
        "#     cudaMemcpy(m2,B,B_size * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "#     dim3 dimGrid(A_rows + BLOCK_SIZE  - 1 / BLOCK_SIZE, B_cols + BLOCK_SIZE - 1 / BLOCK_SIZE);\n",
        "#     dim3 dimBlock(BLOCK_SIZE,BLOCK_SIZE);\n",
        "\n",
        "#     float gpu_elapsed_time;\n",
        "#     cudaEvent_t gpu_start,gpu_stop;\n",
        "\n",
        "#     cudaEventCreate(&gpu_start);\n",
        "#     cudaEventCreate(&gpu_stop);\n",
        "#     cudaEventRecord(gpu_start);\n",
        "#     matrix_multiply<<<dimGrid,dimBlock>>>(m1,m2,result,C_rows,A_cols,C_cols);\n",
        "#     cudaEventRecord(gpu_stop);\n",
        "#     cudaEventSynchronize(gpu_stop);\n",
        "#     cudaEventElapsedTime(&gpu_elapsed_time, gpu_start, gpu_stop);\n",
        "#     cudaEventDestroy(gpu_start);\n",
        "#     cudaEventDestroy(gpu_stop);\n",
        "\n",
        "#     cudaMemcpy(C,result,C_size*sizeof(int),cudaMemcpyDeviceToHost);\n",
        "#     cout << \"GPU result:\\n\";\n",
        "#     print_matrix(C,C_rows,C_cols);\n",
        "#     cout<<\"GPU Elapsed time is: \"<<gpu_elapsed_time<<\" milliseconds\"<<endl;\n",
        "\n",
        "#     cudaEventCreate(&gpu_start);\n",
        "#     cudaEventCreate(&gpu_stop);\n",
        "#     cudaEventRecord(gpu_start);\n",
        "#     matrix_multiplication_cpu(A,B,C,A_cols,C_rows,C_cols);\n",
        "#     cudaEventRecord(gpu_stop);\n",
        "#     cudaEventSynchronize(gpu_stop);\n",
        "#     cudaEventElapsedTime(&gpu_elapsed_time, gpu_start, gpu_stop);\n",
        "#     cudaEventDestroy(gpu_start);\n",
        "#     cudaEventDestroy(gpu_stop);\n",
        "\n",
        "#     cout << \"CPU result:\\n\";\n",
        "#     print_matrix(C,C_rows,C_cols);\n",
        "#     cout<<\"CPU Elapsed time is: \"<<gpu_elapsed_time<<\" milliseconds\"<<endl;\n",
        "\n",
        "#     cudaFree(m1);\n",
        "#     cudaFree(m2);\n",
        "#     cudaFree(result);\n",
        "\n",
        "#     return 0;\n",
        "# }"
      ],
      "metadata": {
        "id": "guAZUmhkIX9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !nvcc -o matmul matmul.cu\n",
        "# !./matmul"
      ],
      "metadata": {
        "id": "zJUkRhbMIppF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}